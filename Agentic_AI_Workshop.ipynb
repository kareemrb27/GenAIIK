{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kareemrb27/GenAIIK/blob/main/Agentic_AI_Workshop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What is Agentic AI?\n",
        "Agentic AI refers to AI systems designed with autonomous decision-making capabilities, enabling them to perceive, reason, and take actions dynamically. These systems leverage multi-agent architectures,and LLMs to perform complex tasks with minimal human intervention. They are widely used in automation, cybersecurity, finance, and enterprise AI for intelligent workflows. Tools like LangChain, CrewAI, AutoGen, and LlamaIndex facilitate building and orchestrating these AI agents.\n",
        "\n",
        "<center><img src=\"https://cdn.prod.website-files.com/66c435ec15ed715aec9ee3fe/66fd1383a0e470c48179a973_66fd136aff11aa6797621e82_What%2520is%2520agentic%2520AI.jpeg\" width=600/></center>"
      ],
      "metadata": {
        "id": "z9CdyNUWtUMq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How is it different from Generative AI?\n",
        "\n",
        "<center><img src=\"https://cdn.prod.website-files.com/66c435ec15ed715aec9ee3fe/66e78a95f15da5104e75ac08_66e78a880dcb8cb0f1229412_Agentic%2520AI%2520vs%2520Generative%2520AI.png\" width =600/></center>"
      ],
      "metadata": {
        "id": "AFsV9BGgu7ok"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NS3n2y8wPw5g"
      },
      "source": [
        "## Basics of RAG\n",
        "\n",
        "Before we start coding, lets go over a few questions and get it clarified.\n",
        "\n",
        "### 1. What is RAG?\n",
        "Imagine you're writing an article about climate change, but instead of relying only on what you remember, you search online for recent studies and data to support your writing. RAG works the same way—it combines a powerful AI language model with a search system that retrieves relevant information from an external knowledge source, like a database or documents. This helps generate more accurate and informative responses.\n",
        "\n",
        "### 2. Why is RAG important?\n",
        "RAG is crucial because AI models, like ChatGPT, can sometimes \"hallucinate\" or provide outdated or incorrect information. By retrieving facts from trusted sources before generating responses, RAG ensures the answers are more reliable, up-to-date, and contextually relevant.\n",
        "\n",
        "### 3. What’s the difference between RAG and a standard AI chatbot?\n",
        "A standard chatbot relies only on pre-trained knowledge, which may be limited or outdated. RAG-enhanced chatbots, however, actively retrieve fresh, relevant information from external sources, ensuring better accuracy and up-to-date insights.\n",
        "\n",
        "### 4. What are the key components of RAG?\n",
        "RAG consists of two main parts:\n",
        "\n",
        "- Retriever: Finds the most relevant documents or data from a knowledge base (e.g., a search engine or database).\n",
        "- Generator: Uses the retrieved information to produce a coherent and accurate response.\n",
        "\n",
        "### 5. Usecases in real-life\n",
        "- Customer Support: AI chatbots retrieve knowledge base articles to provide better responses to customer queries.\n",
        "- Healthcare: Doctors can get AI-assisted summaries of patient records and the latest medical research.\n",
        "- Legal Services: Lawyers can search through legal documents and case studies to build stronger cases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-9ZmExzDRva"
      },
      "source": [
        "### Understanding the Limitation of the LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRit5A9KCx20"
      },
      "outputs": [],
      "source": [
        "# Importing the OpenAI library to interact with OpenAI's API services.\n",
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKBjz45zDj6r",
        "outputId": "07b8ec31-d10b-4cd2-ada0-fe7c7b6abe78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API key: ··········\n"
          ]
        }
      ],
      "source": [
        "import os  # Importing the os module to interact with environment variables\n",
        "import getpass  # Importing getpass to securely input sensitive information\n",
        "\n",
        "# Prompting the user to securely enter their OpenAI API key without displaying it on the screen\n",
        "OPENAI_API_KEY = getpass.getpass(\"Enter your OpenAI API key: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7YY7aEjDj9I"
      },
      "outputs": [],
      "source": [
        "# Creating an instance of the OpenAI client using the provided API key.\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtvWPnanDkAj"
      },
      "outputs": [],
      "source": [
        "# Defining the prompt to query the LLM\n",
        "prompt = ''' What was uber's revenue in 2022? '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBFCA_A_DWBp"
      },
      "outputs": [],
      "source": [
        "# Sending a request to the OpenAI API to generate a chat response\n",
        "openai_response = client.chat.completions.create(\n",
        "    model='gpt-3.5-turbo',  # Specifying the model to use;\n",
        "    # Note: An older model chosen for testing purposes because the cutoff is 2021 whereas prompt is querying details about 2022\n",
        "    messages=[{'role': 'user', 'content': prompt}]  # Creating a structured message for the AI model\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WONjF1M1Xs-k"
      },
      "source": [
        "In the above code, while creating a structured message for the AI model,  `role `defines the speaker (user input) and `content` contains the actual query stored in the `prompt` variable.\n",
        "\n",
        "We are structuring the input this way because OpenAI's chat models require a specific format to understand and process conversations effectively. Assigning roles like 'user' helps the AI distinguish between different participants in the conversation, ensuring it provides relevant and context-aware responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "2u-Y1hWlDij2",
        "outputId": "e9a2461d-1309-4952-8a7f-aebf730fdc13"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I cannot provide real-time data as I am an AI programmed with information up to September 2021. I recommend checking Uber's official website or financial reports for the most accurate and up-to-date revenue information for 2022.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Accessing the generated response from the AI model.\n",
        "openai_response.choices[0].message.content\n",
        "# Note:'choices' contains multiple response options, we take the first one ([0]),\n",
        "# 'message' holds the response details, and 'content' extracts the actual text generated by the AI."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJLYV5B_YWGD"
      },
      "source": [
        "### Interpretation:\n",
        "Why is the LLM not able to answer the query?\n",
        "\n",
        "`gpt-3.5-turbo` does not have access to data after 2021 because of its cutoff.\n",
        "\n",
        "#### Do it yourself:\n",
        "Try changing the model to `gpt-4o-mini` and observe how the output changes!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cl4cl9ylD7AF"
      },
      "source": [
        "As you can see above, the LLM we used(gpt 3.5) doesn't have access to the latest data. Now as LLMs get updated, the training cut-off date may or may not have access to more information. However, it's always a good idea to understand how to improve the context of our prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXHhy-hcEMyy"
      },
      "source": [
        "### Making the LLM context-aware\n",
        "\n",
        "Next Step: Let's check Uber's [financial report ](https://s23.q4cdn.com/407969754/files/doc_events/2024/May/06/2023-annual-report.pdf)\n",
        "\n",
        "On Page 54, of the above document it states:\n",
        "\n",
        "\"Revenue was 37.3 billion, up 17% year-over-year. Mobility revenue increased 5.8 billion primarily attributable to an increase in\n",
        "Mobility Gross Bookings of......\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSAk_2EGD1CC"
      },
      "outputs": [],
      "source": [
        "## Let's create the above context for the prompt\n",
        "# Defining a context string with revenue details retrieved from an external source.\n",
        "retrieved_context = '''Revenue was $37.3 billion, up 17% year-over-year. Mobility revenue increased $5.8 billion primarily attributable to an increase in\n",
        "               Mobility Gross Bookings of 31% year-over-year.'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Irw2unBKFb0M"
      },
      "outputs": [],
      "source": [
        "## Let's modify our prompt now\n",
        "# Creating a prompt by embedding the retrieved context into a question for the AI model.\n",
        "\n",
        "prompt = f\"What was Uber's revenue in 2022? Check in {retrieved_context}\"\n",
        "\n",
        "# Note: The AI is being asked to analyze the given context and provide Uber's revenue for 2022"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R70ZN0eKFoo7"
      },
      "outputs": [],
      "source": [
        "## Let's ask the LLM again\n",
        "openai_response = client.chat.completions.create(\n",
        "    model = 'gpt-3.5-turbo',\n",
        "    messages = [{'role': 'user', 'content': prompt}])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "09ddo9F1Fs-w",
        "outputId": "4c09fd8c-05e0-4877-8c93-8a10c33ccc7b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Uber's revenue in 2022 was $37.3 billion.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Accessing the generated response from the AI model.\n",
        "openai_response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LuE9mCnbR7u"
      },
      "source": [
        "### Interpretation:\n",
        "How is the LLM able to answer the same question now?\n",
        "\n",
        "The LLM can now answer the question accurately because the relevant financial data is explicitly provided in the `retrieved_context`, allowing the model to reference it directly instead of relying on its pre-trained knowledge."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfpLPTtDG57l"
      },
      "source": [
        "As you saw in the example above, we\n",
        "\n",
        "- **retrieved** the context from an external source\n",
        "- **augmented** our prompt that passes to the LLM, and\n",
        "- **generated** the response\n",
        "\n",
        "This is Retrieval Augmented Generation in a nutshell!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKzjA8hmHtaA"
      },
      "source": [
        "### Basic RAG app architecture\n",
        "\n",
        "In the previous example, we ***manually*** retrieved the context from the given file which for all purposes is impractical!\n",
        "\n",
        "Therefore, we have to devise a strategy that enables us to:\n",
        "\n",
        "- Take the query from the user\n",
        "- Identify the documents from the external source that might be relevant for the query.\n",
        "- Pass those documents' information as context to the LLM\n",
        "- LLM then generates the final response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msqpnuzuJHYY"
      },
      "source": [
        "To do the above, we can follow a simple standard architecture as shown below (Image source - https://huyenchip.com/2024/07/25/genai-platform.html)\n",
        "\n",
        "<center><img src=\"https://huyenchip.com/assets/pics/genai-platform/3-rag.png\" width=500 height=400/></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXm08cxzLsia"
      },
      "source": [
        "As you can see in the above image, the retriever would be the key component of this entire architecture.\n",
        "\n",
        "To build the retriever, we have to follow these steps:\n",
        "\n",
        "- Connect to the document source\n",
        "- Break the documents down to manageable chunks.\n",
        "   - This is due to the fact that taking in the entire document source for building the context will exceed the token limits of the LLM.\n",
        "   - This process is also called **Chunking**.\n",
        "- Perform a search for the most relevant chunks based on the given query.\n",
        "- Pass those relevant chunks to the LLM.\n",
        "\n",
        "For performing the search or retrieval process, we will be following an **embedding-based approach.**\n",
        "\n",
        "<center><img src=\"https://cdn.prod.website-files.com/640248e1fd70b63c09bd3d09/653fd23f1565c0c1da063efc_Semantic%20Search%20Text%20Embeddings%20(1).png\" width =500/></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MPW_40jNLDn"
      },
      "source": [
        "### Understanding Embedding based approach\n",
        "\n",
        "In the embedding based approach:\n",
        "\n",
        "- We convert the document chunks in the database to vector embeddings and store it in a vector store.\n",
        "\n",
        "- Convert the given user query to an embedding.\n",
        "\n",
        "- Find the document chunks whose vector embeddings are closest to the given query embedding using a vector search algorithm like FAISS (Facebook AI Similarity Search)\n",
        "\n",
        "<center><img src=\"https://miro.medium.com/v2/resize:fit:1400/1*h_btyitJX79d-gFE8RaMQg.png\" width=500/></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7aMQOXtON5U"
      },
      "source": [
        "### Tools for building the RAG App\n",
        "\n",
        "Now that we are familiar with the overall architecture, we can now go ahead and structure the tools that we'll use for the upcoming demonstration:\n",
        "\n",
        "- OpenAI LLM (model - GPT 4o-mini): This will be our primary model for generating the responses\n",
        "- LangChain: Langchain is a powerful framework for orchestrating different layers in the RAG app. We shall use this to build the retriever end-to-end and also connect with other tools for tasks such as\n",
        "    - Chunking - RecursiveCharacterTextSplitter\n",
        "    - Embedding Model - OpenAIEmbeddings\n",
        "    - Vector Search Model - FAISS\n",
        "- Gradio: This will help in building a simple UI at the end."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQfzsw36du3S"
      },
      "source": [
        "## Problem Statement\n",
        "Shopping online can be overwhelming. You search for a simple pair of shoes, but end up scrolling through countless options—many irrelevant, some too expensive, others just not right. Traditional search engines rely on keywords, often missing what you truly need.\n",
        "\n",
        "Let's build an AI-powered product discovery chatbot changes this. Using advanced language models and vector-based search, it goes beyond keywords to understand your intent, offering personalized, context-aware recommendations in seconds.\n",
        "\n",
        "<center><img src=\"https://www.pranathiss.com/static/assets/images/ai-powered-chatBot.webp\" width=500/></center>\n",
        "\n",
        "This smart solution enhances the shopping experience, increasing customer satisfaction, engagement, and conversions. The future of e-commerce is here—smarter, intuitive, and built for you.\n",
        "\n",
        "### Dataset Used:\n",
        "The given dataset contains information about various products, including their IDs, descriptions, and specifications. Below is a detailed description of each column and the type of data it contains.\n",
        "\n",
        "You can download the entire dataset [here](https://www.kaggle.com/datasets/piyushjain16/amazon-product-data).\n",
        "Or you can download the smaller sample dataset [here](https://drive.google.com/file/d/1ohd9xo19HmDVIwpXPf_IyMkwr29gJJxR/view?usp=drive_link).\n",
        "\n",
        "#### Column Descriptions:\n",
        "- `PRODUCT_ID (Integer)`\n",
        "A unique identifier assigned to each product.\n",
        "Example: 1925202, 2673191\n",
        "- `TITLE (String)`\n",
        "The name or title of the product, usually a brief summary.\n",
        "Example: \"ArtzFolio Tulip Flowers Blackout Curtain for D...\",\n",
        "\"Marks & Spencer Girls' Pyjama Sets T86_2561C_N...\"\n",
        "- `BULLET_POINTS (List of Strings / NaN)`\n",
        "A list of key product features and benefits in bullet format.\n",
        "- `DESCRIPTION (String / NaN)`\n",
        "A detailed textual description of the product, including specifications, features, and usage instructions.\n",
        "Example: \"Specifications: Color: Red, Material: Aluminium...\"\n",
        "- `PRODUCT_TYPE_ID (Integer / NaN)`\n",
        "A numeric identifier indicating the type or category of the product.\n",
        "Example: 1650, 2996, 7537\n",
        "- `PRODUCT_LENGTH (Float)`\n",
        "The length of the product, likely measured in millimeters or inches.\n",
        "Example: 2125.98, 393.7, 748.031495"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2OGXS6YSl5Y"
      },
      "source": [
        "### Steps:\n",
        "\n",
        "1. **Data Preparation**:\n",
        "   - Load and process the dataset using pandas\n",
        "\n",
        "2. **Vector Store Setup**:\n",
        "   - Convert product descriptions into embeddings.\n",
        "   - Store embeddings in a vector database.\n",
        "\n",
        "3. **Building the Chatbot**:\n",
        "   - Use LangChain to create an LLM pipeline.\n",
        "   - Develop a simple chatbot to answer product-related queries.\n",
        "\n",
        "4. **Creating a UI**:\n",
        "   - Implement a Gradio-based UI for user interaction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ekric37zU6aV",
        "outputId": "74971c49-ce42-404f-a65f-6865f2e209c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchainhub\n",
            "  Downloading langchainhub-0.1.21-py3-none-any.whl.metadata (659 bytes)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchainhub) (24.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchainhub) (2.32.3)\n",
            "Collecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub)\n",
            "  Downloading types_requests-2.32.0.20241016-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchainhub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchainhub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchainhub) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchainhub) (2024.12.14)\n",
            "Downloading langchainhub-0.1.21-py3-none-any.whl (5.2 kB)\n",
            "Downloading types_requests-2.32.0.20241016-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: types-requests, langchainhub\n",
            "Successfully installed langchainhub-0.1.21 types-requests-2.32.0.20241016\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.31 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.3.31)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.59.9)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
            "  Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.31->langchain-openai) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.31->langchain-openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.31->langchain-openai) (0.3.0)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.31->langchain-openai) (24.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.31->langchain-openai) (2.10.5)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.31->langchain-openai) (9.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.31->langchain-openai) (4.12.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain-openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.31->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.31->langchain-openai) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.31->langchain-openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.31->langchain-openai) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.31->langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.31->langchain-openai) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.3.0)\n",
            "Downloading langchain_openai-0.3.2-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken, langchain-openai\n",
            "Successfully installed langchain-openai-0.3.2 tiktoken-0.8.0\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.15)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.11)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.31 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.31)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.5)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.0)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.5)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.31->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.31->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.31->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.31->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.15-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.11)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.15)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.31 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.31)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.0)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.15->langchain-community) (0.3.5)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.15->langchain-community) (2.10.5)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.31->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.31->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.31->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.31->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.15->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.15->langchain-community) (2.27.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
            "Downloading langchain_community-0.3.15-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
            "Downloading marshmallow-3.26.0-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.15 marshmallow-3.26.0 mypy-extensions-1.0.0 pydantic-settings-2.7.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.9.0.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Downloading faiss_cpu-1.9.0.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.9.0.post1\n",
            "Collecting gradio\n",
            "  Downloading gradio-5.13.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.7-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.6.0 (from gradio)\n",
            "  Downloading gradio_client-1.6.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.27.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.5)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.5)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.9.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.6.0->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.6.0->gradio) (14.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.17.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.13.1-py3-none-any.whl (57.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.6.0-py3-none-any.whl (321 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.8/321.8 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.7-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.9.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m98.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.7 ffmpy-0.5.0 gradio-5.13.1 gradio-client-1.6.0 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.20 ruff-0.9.3 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.45.3 tomlkit-0.13.2 uvicorn-0.34.0\n"
          ]
        }
      ],
      "source": [
        "# Installing the LangChain Hub package to access and manage pre-built AI chains, prompts, and agents.\n",
        "!pip install langchainhub\n",
        "\n",
        "# Installing the LangChain OpenAI integration to use OpenAI models within LangChain workflows.\n",
        "!pip install langchain-openai\n",
        "\n",
        "# Installing the core LangChain library for building LLM-based applications, including chaining, memory, and retrieval capabilities.\n",
        "!pip install langchain\n",
        "\n",
        "# Installing the community version of LangChain, which includes integrations and tools contributed by the community.\n",
        "!pip install langchain-community\n",
        "\n",
        "# Installing FAISS (Facebook AI Similarity Search) for efficient similarity-based search on text embeddings.\n",
        "!pip install faiss-cpu\n",
        "\n",
        "# Installing Gradio, a framework to create web-based UIs for AI models and applications easily.\n",
        "!pip install gradio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqC1rIL7IyXt"
      },
      "outputs": [],
      "source": [
        "# Importing the KaggleHub library to interact with datasets and models available on Kaggle.\n",
        "import kagglehub\n",
        "\n",
        "# Importing the CSV module for reading and writing CSV files.\n",
        "import csv\n",
        "\n",
        "# Importing pandas for data manipulation and analysis.\n",
        "import pandas as pd\n",
        "\n",
        "# Importing numpy for numerical operations and handling arrays efficiently.\n",
        "import numpy as np\n",
        "\n",
        "# Importing os to interact with the operating system, such as environment variables and file paths.\n",
        "import os\n",
        "\n",
        "# Importing getpass to securely handle user input (e.g., API keys or passwords).\n",
        "import getpass\n",
        "\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9Vphy17StbK"
      },
      "source": [
        "### STEP 1: Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sh9WpGhWRpCU",
        "outputId": "a0f5ea2d-8951-490c-e45c-690eb4b3865a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0XiPvpp1FxKb"
      },
      "outputs": [],
      "source": [
        "# Loading the data\n",
        "# df = pd.read_csv(\"/content/gdrive/MyDrive/datasets/sample_dataset.csv\",index_col=0)\n",
        "df = pd.read_csv(\"/content/gdrive/MyDrive/IK/project_based/sample_dataset.csv\", index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.to_csv(columns=['DESCRIPTION'], sep='\\t', index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrTfxYlPD3ll",
        "outputId": "be9aee4a-398c-443f-cd2a-db420b88a6bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DESCRIPTION\n",
            "\"\"\n",
            "\"\"\n",
            "Specifications: Color: Red, Material: Aluminium, Voltage: 12V, dB: 130 dB (around), Material: Aluminum Pump Head + Steel Pump Body + ABS Shell and Parts DB output: 130db Voltage: 12v Sound Type: Dual Tone Application: 12V Voltage Vehicles With Battery Above 20A Package included: 1 x Dual Tone Air Horn Compatible With SX4\n",
            "AISHAH Women's Lycra Cotton Ankel Leggings. Brand: ALISHAH Length: Ankel Length Leggings. Size Chart Medium: 28 - 30 inch Large: 30 - 32 inch X-Large: 32 - 34 inch 2X-Large: 34 - 38 inch The color fade will not be there in washing. This cotton stretch leggings is designed to provide absolute comfort and body fit. Pair it with short or long kurta for modern look. High on style, fit and finish, this leggings is sure to lend you a sophisticated look. Please wash the dark colors separately in order to improve the product life. Disclaimer: Product color may slightly vary due to photographic lighting sources or your monitor settings. Please order according to your waist size mentioned in size chart\n",
            "\"\"\n",
            "HINS Brings you the most Elegant Looking Pot with Stand for durable and long life Pot Stands for your lovely garden space, office and home. HINS is one of the best choice when it comes to indoor plants. It makes a good choice for housewarming gift. This beautiful product will take center stage with its sprawling design when planted with a plant. The metal stands are painted with powder-coated paint that will protect the galvanized iron from rusting. It will also prevent the color from fading. Each planter pot is removable for easy mobility, allowing you to switch out plants depending on your mood Note- Monitors are not calibrated same, item color displayed in photos may be showing slightly different from the real object. Please take the real one as standard. Please allow 0~2cm errors due to manual measurement.\n",
            "\"\"\n",
            "<p><strong>Aluminum Foil Stickers-good kitchen helper for mom and wife.&nbsp;</strong><br><br><strong>Specification: &nbsp;</strong><br><strong>-Materials: high-quality PVC &nbsp;</strong><br><strong>-Size: 2 MT&nbsp;</strong><br><strong>-Color: Silver &nbsp;</strong><br><strong>-Friendly note: Please buy enough rolls at a time to make sure that these wallpaper comes from the same batch to avoid color difference. &nbsp;</strong><br><strong>-This Aluminum Foil Stickers can be used for any dry, clean and smooth surface.&nbsp;</strong><br><br><strong>Features: &nbsp;</strong><br><strong>1.High temperature resistant material is suitable for kitchen, which resists temperatures up to 250 Celsius. It can be used for a long time and will not deform. &nbsp;</strong><br><strong>2.Easily to cut up: A grid line in square on the back, easy for you get the size you need when you cut.&nbsp;</strong><br><br><strong>How to use? &nbsp;</strong><br><strong>1.Before sticking the kitchen oil proof wallpaper, please clean and dry surface with mild soap and water. Make sure that surface is flat and without any carve. &nbsp;</strong><br><strong>2.Just cut out the size you want. &nbsp;</strong><br><strong>3.Use dishcloth or card to remove any air bubbles.&nbsp;</strong><br><br><strong>Package Included: &nbsp;</strong><br><strong>1 × Kitchen Backsplash Wallpaper&nbsp;</strong><br><br><strong>100% SATISFACTION GUARANTEED: &nbsp;</strong><br><strong>We are always available to provide professional customer service before and after your purchase, so don't wait any longer and enjoy it right now.&nbsp;</strong><br><br>&nbsp;</p>\n",
            "\"\"\n",
            "Transform your home, workplace or hotel room into your personal aromatherapy oasis! With elegantly designed diffusers and aroma diffuser oils, you can infuse essential oils into any setting and create a spa-like experience anywhere life takes you. 10 bottle each of Lavender, Rose, Tea Tree, Rosemary, Jasmine, Rajnigandha, Eucalyptus, Lemongrass, Orchid & Sandalwood fragrance.\n",
            "3NH Glasses Goggles Anti Fog Antis Windproof Anti Dust Resistant\n",
            "\"\"\n",
            "\"\"\n",
            "\"\"\n",
            "Segovia bottle consists of stainless steel which provides a robust build for any occasion whether it be hiking, cycling, camping, gym or just to the office. Its special design along with its material is a testament to its durability. The bottle and cap are made from BPA free materials and food grade steel. It's free of toxins and safe for you to use and drink from.Single layer wall stainless steel water bottle,no heat preservation function, be careful when adding hot water.\n",
            "\"\"\n",
            "\"\"\n",
            "\"\"\n",
            "\"\"\n",
            "MASTER OF THE RINGS\n",
            "\"\"\n",
            "<b>Welcome to our store. We aim to offer unique and special case for you. </b><br> <b>Compatibility</b><br> Compatible with iPhone 13. <br>This case is durable, sturdy and scratch-resistant, perfect for self use or gifts.<br> <b>Features</b><br> ❤Made of soft resilient TPU material, this case is durable and lightweight, easy to take on and off. <br> ❤Raised camera and screen edges provide best protection for phones from falls, scratches or bumps. <br>Designed with four air cushion corners, it perfectly mitigates pressure from drops o falls.<br> ❤Independent buttons and precise cutouts. <br>This case fits buttons, camera, speakers, and ports perfectly.<br> ❤The print is vivid and clear, making your phone look unique and and aesthetic. <br>We use supreme scratch resistant ink, the pattern will not peel over time.<br> <b>PACKAGE LIST</b><br> Including 1 x Phone Case<br>\n",
            "\"\"\n",
            "\"\"\n",
            "\"\"\n",
            "PACK OF 65 INCENSE CONES. Best Quality Low Smoke Dhoop Cones By JSR Cart. Dhoop involves the offering of fragnance before the picture of a deity, as a token of respect. It has a pure and clean fragrance It creates such an ambience that your prayer reaches the divine and is completed Natural & Herbal.\n",
            "\"\"\n",
            "<p>These Stylish Earring for Women and Girls are handcrafted with love and will add a touch of spirituality to your look. It is suitable with all outfits &amp; may be worn at any occasion.</p> <p>Redgem has huge collection of fine jewellery of silver and precious gems for women.</p> <p>◆&nbsp;<strong>Pure Sterling Silver Earring for girls and Women&nbsp;</strong>makes it very simple and attractive.</p> <p>◆ <strong>Design</strong>: A Stylish Pure Sterling Silver Product with beautiful design</p> <p>◆ <strong>Authenticity</strong>: product comes with a S925 Mark which serves as a proof of identity</p> <p>◆&nbsp;<strong>Quality</strong>: Fine of silver with nickel free, lead free alloy which is non- allergic to all skin types.</p> <p>◆&nbsp;<strong>Occasion</strong>: suits to wear in any occasion like daily, party , wedding and festival.</p> <p>◆&nbsp;<strong>Perfect Gift:</strong> Ideal for Valentine, Birthday, Anniversary gift for your loved ones. Excellent gift for festivals celebrations and all precious moments of happiness.</p>\n",
            "\"Size S upper chest circumference:64-72cm/25.2\"\"-28.35\"\"<br> Size M upper chest circumference:72-82cm/28.35\"\"-32.28\"\"<br> Size L upper chest circumference:82-88cm/32.28\"\"-34.65\"\"<br> Size XL upper chest circumference:88-94cm/34.65\"\"-37.01\"\"<br> Size XXL upper chest circumference:94-98cm/37.01\"\"-38.58\"\"<br>The Model:height 100cm,weight 50KG,his comfortable size is M.<br>BaronHong is a new brand ,aimed to bring you a better life.All tradeworks belongs to BaronHong.\"\n",
            "1:64;First Editions0\n",
            "Antique traditional handmade peacock wall decor Handmade Rajasthani bell wall hanging with bells for Bell shaped Wind chime for your house or office decor and positive atmosphere. Wind chimes sound creates peace and is a Feng Sui. Its a peacock wall decoration items makes home beautiful and sounds like a wind chime that contains handmade & hand painted elephants hanging in strings with golden bells that makes beautiful and smooth sound. The product will be exactly the same as show in the picture.\n",
            "<p>FMB120 small and professional tracker with internal high gain GSM and GNSS antennas, which is able to collect device coordinates and other useful data and transfer them via GSM network to server.&nbsp;</p><p>This device is perfectly suitable for applications where location acquirement of remote objects is needed: fleet management, car rental companies, taxi companies, public transport, logistics companies, personal cars and so on. FMB120 can perform tasks on remote objects, such as monitoring engine status, controlling truck’s door etc.</p><p><strong>Features:</strong></p><ul><li>Support New generation GSM/GNSS module</li><li>Cost Effective Small Light weight GPS Device</li><li>Dual SIM and Bluetooth Connectivity</li><li>Various Vehicle CAN Adapters</li><li>FMB Immobilizer</li><li>SOS, Geo-Fence, Vibration, Movement alarms and notification</li></ul><p><strong>Specifications:</strong></p><ul><li>GPS Chipset: MTK high Sensitivity Chip</li><li>Model: FMB120</li><li>Location Accuracy: &lt;10 Meters</li><li>Voltage Input: 10-30V DC</li><li>Backup Battery: 170mAh</li><li>Tracking sensitivity: -165dBm</li><li>Acquisition sensitivity: -144dBm</li></ul><p><strong>Applications:</strong></p><ul><li>Fleet management</li><li>Car Rental, Taxis, Travel Bus.</li><li>Public transport</li><li>Logistics companies</li><li>Personal cars</li></ul><p><strong>Package Included:</strong></p><ul><li>1 GeoShadow FMB120 GPS Tracker</li><li>1 Extension Wire</li><li>1 Relay Wire</li><li>1 Instruction Note</li></ul>\n",
            "The Next Generation Bed Frame - The Premium 18 Inch SmartBase Mattress Foundation by Zinus eliminates the need for a box spring as your memory foam, spring or latex mattress should be placed directly on the Premium SmartBase. Uniquely designed for optimum support and durability the strong steel mattress support has multiple points of contact with the floor for stability and prevents mattress sagging, increasing mattress life. The Premium SmartBase bed frame is 18 inches high with 16.5 inches of clearance under the frame for 4 extra inches of under-bed storage space. With plastic caps to protect your floors and an innovative folding design to allow for easy storage, the SmartBase is well designed for ease of use. Worry free 5-year limited warranty.  Another comfort innovation from Zinus. Pioneering comfort.\n",
            "\"\"\n",
            "\"\"\n",
            "<strong>About YinanLi Dress</strong>:<br />We provide different style of Bridesmaid Dresses, Bridal gowns, Prom Gowns, Cocktail Dresses, Evening Dresses, Party Dresses, Homecoming Dresses, and Celebrity Dresses.<br /><br /><strong></strong> <strong>Prom Dress Details:</strong><br />Material: Satin<br />Neckline: V-Neck<br />Sleeve: Sleeveless<br />Back: Open Back<br />Closure: Back Zipper<br />Length: Long/Floor Length<br />Occasion: This elegant satin prom dress is suit for wedding party, bridesmaid, prom, evening, homecoming, wedding, birthday party, dance party, graduation, celebrity, red carpet and other formal or special occasions. <strong><strong></strong></strong><br /><br /><strong></strong><strong>Custom Size:</strong><br />We could make custom size and color freely, if you want please email to us when you place the order.<br />1. Bust:<br />2. Waist:<br />3. Hips:<br />4. Height: from head to toe (barefoot)<br /><br />1. Originally Designed: All dresses are designed by the most qualified designers, and the most experienced tailors carry out strict quality inspections in our own factories. Every needle and every thread reflects our passion for service and attention to detail. You will get the most exquisite design<br /><br />2. Could this work as a maternity dress? Since satin fabrics are not elastic, only some imperial waist skirts are suitable for pregnant women. We strongly recommend that you customize the dress, select &quot;custom&quot; in the size area, fill in your size, so we will customize this beautiful prom dress for you.\n",
            "\"\"\n",
            "\"\"\n",
            "Turtleneck Pullover Sweater\n",
            "Capturing the flavour of finely wrought Renaissance-style leather bindings, Paperblanks Midnight Steel 2021 12-Month Diary pays homage to the craft of delicate gold tooling, originally introduced to Europe via the flourishing trade routes to the East. The timeless beauty of an antique leather binding is brought into the present on the cover of this deep blue book.\n",
            "\"\"\n",
            "\"\"\n",
            "Comfortable and light weight for daily use. Attractive, unique designs. Allows easy access to all buttons, controls and ports of your Phone. The back designs are totally customized designs, these designs on the cases are manufactured by Cleok Associate after you place the order. Protects your Phone from scratches and damage. This case covers full back side of your Phone and need not to replace the original back cover. High Quality finish case.Easy to install and remove.\n",
            "Pooplu Womens Cotton Plain Combo Pack of 3 MultiColour T shirt With 180 GSM Pure Cotton Regular Fit Tshirt\n",
            "\"\"\n",
            "\"\"\n",
            "Serve cool drinks in our 30 oz Jumbo Plastic Margarita Glass Caribbean Blue! Features a Caribbean Blue plastic jumbo margarita glass. Holds 32 oz of your choice of liquid. Includes 1 margarita glass per package.\n",
            "adidas Predator 18+ FG- Black 7.5\n",
            "\"\"\n",
            "<p>✔ This wool for knitting is good as a crochet yarn wool and can be crafted as jumpers, sweaters, etc.<br></p><p> ✔ Knitting yarn baby wool is made of 100% acrylic. This high-quality knitting wool yarn set can be used for a variety of craft projects, hand crocheting, baby blankets, hats, booties, wool socks, kit and other baby and kids items.&nbsp;<br></p><p>✔&nbsp;This wool for knitting is good as a crochet yarn wool and can be crafted as jumpers, sweaters, etc.</p><p>✔&nbsp;Branded wool knitting provides satisfaction and quality of knitting experience.<br></p><p>✔&nbsp;This variety of wool contains many colors like Black, Violet, Blue, White, Red, Green, multi,&nbsp; etc.<br></p><p>✔&nbsp;This crochet wool is a Gauge 3 wool, it's not a chunky thick wool. It's a very soft thread yarn comes in many colors. Can be hand washet and delicat machine wash at 40° C.<br></p><p>✔&nbsp;Similar types of wools are - Vardhman rosemary wool, Vardhman microshine wool, oswal wool thread yarn for knitting.<br></p><p>✔ Note - This is not a yarn thick chunky wool. Not a thick wool for knitting. It's a needle, crochet yarn acrylic avaliable in gm and kg.<br></p>\n",
            "\"\"\n",
            "\"\"\n",
            "\"\"\n",
            "\"\"\n",
            "\"\"\n",
            "This is a 12 x 18 Inch Size Poster Print, printed on high quality matte finish poster paper. No cheap paper used. Quality is Guaranteed.\n",
            "\"\"\n",
            "Fihapyli Workout Tank Tops for Women Sleeveless Yoga Tops for Women Mesh Back Tops Racerback Muscle Tank Tops Workout Tops for Women Backless Gym Tops Running Tank Tops Activewear Tops Green M\n",
            "\"\"\n",
            "<p><b>Feature:</b></p><p>1. 480X320 HD resolution, only a few IO can light up the display<br>2. With memory card slot to facilitate the expansion of the experiment, provide a wealth of sample programs<br>3. Multifunctional use, can be used for other display functions through the signal transmission line<br>4. Small size, easy to carry and store, convenient to use and with good performance<br>5. Strict quality control and quality assurance, high safety factor, can be used with peace of mind</p><p><br></p><p><b>Spec:</b></p>Item Type: LCD Screen ModuleSize: Approx. 3.5 (inch)<br>Type: TFT<br>Driver Chip: ILI9488<br>Resolution: 480 x 320 (Pixel)<br>Module Interface: 4-wire SPI interface<br>Effective Display Area: (AA area) 48.96 x 73.44mm / 1.9 x 2.9in&nbsp;<br>Module PCB Floor Size: Approx.56.34 x 98mm / 2.2 x 3.9in&nbsp;<br>VCC Power Supply Voltage: 3.3V~5V<br>Logic I/O Voltage: 3.3V (TTL) <p><br></p><p><b>Package List:</b></p>1 x LCD Screen Module\n",
            "\"<b>Under the Bed Storage Containers,Underbed Storage Bins Organizer for Blanket Clothes, Tidy Up Your Closet and Shelf,with Clear Window,2 Sturdy Zippers,4 Strong Handles Set of 2 Coffee with Lantern Printing</b><br> <b>COLOR:white with lantern printing</b><br> <b>SIZE:39.37\"\"x19.68\"\"x5.90\"\"</b><br> <b>Comforter breathable storage bag, Double strong zippers easy to carry or grab fits great under your bed</b><br> -Closet Soft Storage Bag With Clear Window Zippers and Handles ,classify Clothing,Comforters,Holiday Ornaments,Quilts, Blankets.<br> -Whether you want to tidy up your closets or create extra storage space under the bed, this versatile underbed organizer has got you covered in perfect style.<br> -Not only for under the bed, also for guestroom, down the attic stairs, your apartment with limited space to spare. They fold down to flat square when not in use.<br> -The jumbo blanket storage bag?is sturdy and durable.\"\n",
            "\"\"\n",
            "Save space and get quick and easy access to your favorite foods and pantry items, you will save time and have a better idea of which food items you have on hand, organize bins by food categories. It also works great in the garage, bathroom, or bedroom for organizing craft supplies, sewing supplies, office supplies, classroom items, decorations, makeup, smaller bedroom items. Store items such as ribbon, tweezers, nail clippers, or some small things to make any junk drawer look neater. These are also used for tables and desks to store and organize your food or deal with small things. Great inside the refrigerator or freezer that organize them and keep the yogurt, meat, cheeses, eggs, fruit, or vegetables fresh.\n",
            "\"\"\n",
            "Come and Take It Black Flag Embroidered Patch Iron-On Gonzales Texas Revolution\n",
            "\"\"\n",
            "<p><strong>Do You Want Your Device To Look Different Than The Rest?</strong></p> <p>You&rsquo;re in the right place because we&rsquo;ve got exactly what you are looking for! This Skin is the perfect way to show off your style! Or with hundreds of other Skins designs, you can be sure to find one that you&rsquo;ll love, and that will show off your unique style!</p> <p><strong>Do You Want To Protect Your Device?</strong></p> <p>With our Skins your Device is protected from scratches, dings, dust, fingertips, and the wear-and-tear of everyday use!</p> <p>Cover your Device with a beautiful, stylish decal skin and keep it protected at the same time!</p> <p>Easy to apply, and easy to remove without any sticky residue!</p> <p>Make your favorite gear look like new, and stand out from the crowd!</p> <p><strong>Order With Confidence</strong></p> <p>Our Skins are durable, reliable, made in our state-of-the-art production facility in the India.</p> <p><strong>Product Details:</strong></p> <ul> <li>&nbsp;Vinyl decal sticker</li> <li>&nbsp;NOT A HARD CASE</li> <li>&nbsp;Ultra-Thin, Ultra-Durable, Stain Resistant</li> <li>&nbsp;Hundreds of different designs</li> <li><strong>&nbsp;Device is not included.</strong></li> </ul>\n",
            "The Remora Climbing Shoe is Mad Rock's do-it-all slipper for climbers who can't have separate shoes for boulders, sport routes, and gyms. With a moderately stiff, slightly downturned design, the Remora performs on any climb at steep to vertical angles. Science Friction rubber edges on jibs with ease, and it encapsulates the forefoot for toe-hooking prowess. The SynFlex upper conforms to your foot without much stretch.\n",
            "\"\"\n",
            "24K Gold printed Wall hanging Bone china Plates with stand you can use iit anywhere in house its 7 inches single piece plate\n",
            "This beautifully handcrafted Lehenga by Attiris will make you look simply elegant giving an ethnic vibe. Elegance is the beauty that never fades. This is a superb outfit for every function. Lehenga has 3 meter flair and is semi stitched fits upto 42 inches at waist. The blouse is made of embroidered satin giving you a glamorous look for your perfect evening. Dupatta is made of high quality soft butterfly net and is 2.5 meter long. This Ghagra is generally worn for celebratory occasions like weddings and festivals and also wearable as chaniya choli and lancha. Go for high heels and a gold clutch. All for a bonafide wedding ensemble.\n",
            "\"\"\n",
            "GLAVON ADS Face & Body Scrub 200 gm with goodness of Natural Apricot Extract , 200 gm Combo of MN BB Cream Rose Extract- Shade C,Dark Ivory - [ Combo of 4 Items ]\n",
            "\"Laptop skin is compatible with laptops screen sizes ranging from 14.1 inches to 15.6 inches. Trimning of the skin would be required as per your laptop size. The skins by MSI are easy to install & remove without leaving any gum or residue. <br/> laptop skins enable you and your device a unique look which are cool, trendy & personalized. These skins protect your device from dirt, minor scratches & dullness, increasing its life & re-sale value. Specification: <br/>Dimensions (W x H): 15 inches x 10 inches<br/>Compatibility: Most laptops with screen sizes ranging from 10\"\" to 15.6\"\" <br/>Instructions for application:<br/>1. Make sure your laptop is clean. Wipe it off with a soft cloth. The laptop should be free of dust, fat or grease - otherwise the laptop skin may not stick to your laptop as well as it's supposed to.<br/>2. Take the measurement of the applying area<br/>3. Trim the exact size before applying with a blade/scissors<br/>4. Align the laptop skin on your laptop, take care that you put it on straight and in the exact position that you want to place it<br/>5. Remove only one side of the liner from sheet, align to the applying surface and start attaching them slowly<br/>6. Proceed carefully with the use of a clean cloth and/or a plastic card (i.e. ATM card) to assure no air bubbles remain until the liner is removed.\"\n",
            "This unique White Ceramic ring is laser engraved with a piano keyboard design, crafted from Hi-Tech Ceramic. It looks amazing and is very comfortable to wear. It requires little to keep it clean. With its reasonable price and beauty, it is a great gift. Ideal for use as a wedding ring. All of our Ceramic rings are Hypoallergenic and scratch resistant. Choose from 6mm or 8mm Widths. The piano pattern is continuous around the outside of the ring.\n",
            "\"\"\n",
            "\"\"\n",
            "\"\"\n",
            "The complementary design and sturdy build quality are some of the features that separate this universal tablet stand from other brands of tablet holders. Its unique combination of a solid plastic construction, soft silicon pads and a Non-slip rubber surface provides 100% protection, stability and mounting support for your device. The design of the holder helps to prevent your tablet or any other mounted device from getting scratched. This Universal phone stand is not only lightweight and portable but also fully retractable to support multiple mounting options and easy use on-the-go. Multi Angles, Landscape and Portrait Display Modes! This universal mobile phone holder and tablet stand has a very complimentary build resourcefully designed to offer you more for less. Its unique design allows you to conveniently use any mounted device in either portrait or landscape mode, so you can have a convenient viewing experience. Unlike other mounts for tablets and smartphone, this universal iPad stand has a well-balanced design that allows you to comfortably watch movies, read books, and play games on any mounted devices without worries. Its Adjustable angle allows you to use your tablets in landscape or portrait orientation, even if your device is encased. A Multi-Function Stand for all your Smart devices Having a stand that offers you more than one mounting options will come in handy if you have more than one device. With this in mind, we decided to design this mount to offer you just that. Unlike regular cell phone holders, mobile phone stands and tablet holders, this universal tablet display stand adjusts nicely to fit 4”to 12”smartphones, tablets and other smart devices without hassles.\n",
            "\"\"\n",
            "\"\"\n",
            "Note - Item Doesnt Have Back Camera Or Speaker Hole And For Its Usage The Tablet Needs To Be Removed From Cover.The Really Smart Cover Makes Tablet Do Things No Other Cover Can. The Smart Cover Doesn't Just Protect Tablet, It Keeps It Ready To Go Whenever You Are.Magnetic Locks To Lock Your Tablet When Not In Use And Hence Making It Totally Safe.You Can Put It Stand Up For Watching Videos Or Lay It Down For Typewriting.Ultra Slim & Lightweight Design.Soft Synthetic Leather Outer Gives Tactile And Aesthetic Appeal And Full Protects Your Latest Tablet Whilst The Leather Interior Adds Strength And Durability To The Case.`\n",
            "\"\"\n",
            "\"\"\n",
            "<p>These pants are adjustable the waist by drawstring makes them incredibly versatile and comfortable. 100% rayon. The material is silky soft and lightweight. Hand wash is recommended.</p><p><strong>Measurement</strong></p><p><strong>Size S (US 0-2)</strong></p><ul><li>Waist circumference: 22.8 - 42.7 inches (58 - 108.4 cm)</li><li>Leg Length: 41.3 inches (105 cm)</li></ul><p><strong>Size M (US 4-6)</strong></p><ul><li>Waist circumference: 25.2 - 46.6 inches (64 - 118.4 cm)</li><li>Leg Length: 41.3 inches (105 cm)</li></ul><p><strong>Size L (US 8-10)</strong></p><ul><li>Waist circumference: 27.6 - 50.7 inches (70 - 128.8 cm)</li><li>Leg Length: 41.3 inches (105 cm)</li></ul><p><strong>Size XL (US 12-14)</strong></p><ul><li>Waist circumference: 29.9 - 54.6 inches (76 - 138.8 cm)</li><li>Leg Length: 41.3 inches (105 cm)</li></ul><p><strong>Size 2XL (US 16-18)</strong></p><ul><li>Waist circumference: 32.3 - 58.3 inches (82 - 148 cm)</li><li>Leg Length: 41.3 inches (105 cm)</li></ul><p><strong>Size 3XL (US 18-20)</strong></p><ul><li>Waist circumference: 34.6 - 62.2 inches (88 - 158 cm)</li><li>Leg Length: 41.3 inches (105 cm)</li></ul><p><strong>Size 4XL (US 20-22)</strong></p><ul><li>Waist circumference: 37 - 66.1 inches (94 - 168 cm)</li><li>Leg Length: 41.3 inches (105 cm)</li></ul>\n",
            "\"\"\n",
            "\"\"\n",
            "Body by wacoal seamless underwire is sleek and modern\n",
            "\"\"\n",
            "\"\"\n",
            "Dr. Flex Ozette Super Sensitive toothbrush is made with Special super Soft Tapered filaments for sensitive gums. Packed in an Anti - Bacterial container which can be reused to keep your toothbrush safe from germs, etc. The handle is specially designed for a better grip & large head.<p><b>Its 100% Tapered Filaments provide safe and effective cleaning of teeth and gums.</b></p><p><b>Additional Features: </b><li>Washable and reusable.</li><li>You can get the protection you need and save money at the same time.</li><li>The anti - bacterial hygiene container is reusable and great for Home and Travel use.</li><li>This product will be delivered in assorted colors.</li><li><b>This Product is Made in India.</b></li><p><b>Gives you healthy teeth and a white smile!</b></p><b>Disclaimer: </b><br>This product will be delivered in assorted colors.\n",
            "Alize Angora Gold Simli 5% Metallic 20% Wool 75% Acrylic Lot of 2 skn 200gr 1100 ydsYarn Thread Crochet Lace Hand Knitting Turkish Yarn - SATISFACTION GUARANTEE - buy original crocheting yarn, check that you purchase from LIVLOREN seller\n",
            "<p><b>Description:</b></p><p>This unique designed bracket fits for Brompton front carrier block.<br>Adapter size: 11 x 8 cm. Max Loading is 35kg.<br>Designed for Brompton folding bike, no bag frame needed.<br>Made of high-quality ABS PVC, durable and wear-resisting.<br>There are four holes on the plate, easy to install.<br>Convert your favorite small bag or basket into a bike bag.</p><p><b>Specification:</b></p><p>Material: ABS<br>Size: 11x2.5x8cm/4.33x1x3.15inch<br>Max Loading: 35kg</p><p><b>Package Includes:</b></p><p>1 Piece Bike Front Bag Carrier Block Adapter</p><p><b>Note:</b></p><p>Color might be slightly different due to the color calibration of each individual monitor.<br>Please allow slightly measuring deviation due to manual measurement.</p>\n",
            "\"<br><p> <b> Materials: </b>Made of high quality durable linen fabric<br> <b> Features:</b>The Pillow Covers are very durable, environmentally friendly and very comfortable, breathable.It can decorate your sofa and add color to it<br> <b> Size:</b> pillow covers 18x18 inch (45cm x 45cm). Pillow insert is not included.<br><b> Note:</b>This outdoor pillows an invisible zipper and all seams have been over-locked so it is easy to wash it.Invisible zipper improves the appearance and provides easy insertion and removal. <br><p> <b> Care tips:</b><br> 1. Machine Wash in cold water. Do not use bleach.<br> 2. Dry flat or hang to dry. <p> <b> About Wyooxoo：</b><br>\"\"wyooxoo\"\" is the professional home decor manufacturer for over 7 years. we has dedicated to First-Class quality home decor Pillow covers, bringing a touch of freshness and warmth to your Home.<br> We are dedicated to enhancing your purchasing experience and offer a no questions asked refund, If you experience any issues. Simply contact wyooxoo directly through the Amazon messaging system. We are always at your service.</P>\"\n",
            "\"\"\n",
            "\"\"\n",
            "\"Fancy dupatta border golden Colour, light in weight Chiffon Printed Work Dupatta for Womens & Girls The Chiffon Dupatta is favourite for picnic, outdoor, travelling, cycling, dancing and stage performance. Use it as casual or formal wear for office, shopping, daily wear in home, college, family, meetings, festive occasions.work \"\" star zari on whole dupatta with jhalar lace. Fancy dupatta party Wear Fancy dupatta for women in chiffon The dupatta is made with Soft Chiffon fabric which makes it extremely light and comfortable. It is elegant in appearance and features a captivating charm.\"\n",
            "\"\"\n",
            "GlobalNiche Leather Car Key Case Cover for for d Fiesta MK7 ST Focus 3 MK3 MK2 Fusion Ka Ecosport Galaxy Escort Key Ring Car Accessories Color Name Red\n",
            "<ul><li>Pre-Shrunk, Medium Weight, 100% Cotton</li><li>Relaxed, Classic Fit</li><li>Hand-Dyed and Printed Using Soft, Non-Toxic Water-Based Inks</li><li>Reinforced Double-Stitching On All Seams</li></ul>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-3RpjmUS21M"
      },
      "source": [
        "**Constructing the text data**\n",
        "\n",
        "It's useful to use both `Title` and `Description`. To help downstream models understand which content is title and which content is description, we will add a prefix explaining which section is title and which is description. So each row should look like\n",
        "\n",
        "```\n",
        "Title\n",
        "{Title}\n",
        "Description\n",
        "{Description}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MduzbFnMSdNo"
      },
      "outputs": [],
      "source": [
        "## Let's construct the text data\n",
        "# Initializing empty lists to store product descriptions and their lengths\n",
        "product_description = []\n",
        "product_description_len = []\n",
        "\n",
        "# Iterating through each row in the dataframe df2\n",
        "for row in df.iterrows():\n",
        "    product = \"\"  # Initialize an empty string to accumulate product details\n",
        "\n",
        "    # Extracting the product title from the current row\n",
        "    title = row[1][\"TITLE\"]\n",
        "\n",
        "    # Checking if the title is valid (not NaN or missing)\n",
        "    if type(title) != float or not math.isnan(title):\n",
        "        product += \"Title\\n\" + title + \"\\n\"  # Append the title to the product description\n",
        "\n",
        "    # Extracting the product description from the current row\n",
        "    description = row[1][\"DESCRIPTION\"]\n",
        "\n",
        "    # Checking if the description is valid (not NaN or missing)\n",
        "    if type(description) != float or not math.isnan(description):\n",
        "        product += \"Description\\n\" + description + \"\\n\"  # Append the description to the product details\n",
        "\n",
        "    # Check if either title or description was added\n",
        "    added_content = title or description\n",
        "    if added_content:\n",
        "        product = product.strip()  # Remove any leading/trailing whitespace\n",
        "        product_description.append(product)  # Add the formatted product details to the list\n",
        "        product_description_len.append(len(product))  # Store the length of the product description\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rd2Tpb2dTeQc",
        "outputId": "ef16006e-7e1f-48b8-c39c-65999157ec47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of elements 100\n"
          ]
        }
      ],
      "source": [
        "# Checking the length of the data\n",
        "print(f\"Number of elements {len(product_description)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7JLY31mTx0l",
        "outputId": "4820e9f7-04a0-4086-8af3-626d4bf9970a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title\n",
            "PRIKNIK Horn Red Electric Air Horn Compressor Interior Dual Tone Trumpet Loud Compatible with SX4\n",
            "Description\n",
            "Specifications: Color: Red, Material: Aluminium, Voltage: 12V, dB: 130 dB (around), Material: Aluminum Pump Head + Steel Pump Body + ABS Shell and Parts DB output: 130db Voltage: 12v Sound Type: Dual Tone Application: 12V Voltage Vehicles With Battery Above 20A Package included: 1 x Dual Tone Air Horn Compatible With SX4\n"
          ]
        }
      ],
      "source": [
        "# Check a sample product description data\n",
        "print(product_description[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kaPPz4ebT0P4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5e81de0-952f-465a-ca7a-7ae5aa8976bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of items 100\n",
            "Min Length of the description: 18\n",
            "Avg Length of the description: 385.9\n",
            "Max Length of the description: 1834\n"
          ]
        }
      ],
      "source": [
        "# Print the total number of product descriptions processed\n",
        "print(\"Number of items\", len(product_description_len))\n",
        "\n",
        "# Print the minimum length of the product descriptions\n",
        "print(\"Min Length of the description:\",np.min(product_description_len))\n",
        "\n",
        "# Print the average (mean) length of the product descriptions\n",
        "print(\"Avg Length of the description:\",np.mean(product_description_len))\n",
        "\n",
        "# Print the maximum length of the product descriptions\n",
        "print(\"Max Length of the description:\",np.max(product_description_len))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4y4JSH_Svat"
      },
      "source": [
        "### Interpretation:\n",
        "\n",
        "What does the above result signify about the data?\n",
        "\n",
        "\n",
        "*   A minimum length of 18 suggests that some product descriptions might be too brief\n",
        "*  With an average length of 385.9 characters, most product descriptions contain a reasonable amount of information\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRjed6aXUo6j"
      },
      "source": [
        "### STEP 2: Vector Store Setup\n",
        "\n",
        "Let's try to get a few of the basic questions answered about vector stores before we start using it.\n",
        "\n",
        "### What is a vector store?\n",
        "A vector store is a specialized database that stores data in the form of numerical vectors, allowing efficient searching and retrieval based on similarity rather than exact matches.\n",
        "\n",
        "### Why do we need a vector store?\n",
        "Traditional databases rely on exact keyword matches, which can miss relevant information. A vector store helps find similar content by understanding relationships and meaning in data.\n",
        "\n",
        "### How does a vector store work?\n",
        "It converts text, images, or other data into numerical vectors using AI models, then stores these vectors and retrieves similar ones using techniques like cosine similarity.\n",
        "\n",
        "### How does a vector store improve search results?\n",
        "It enables searches based on meaning rather than just keywords, providing more relevant results even if the exact terms don't match.\n",
        "\n",
        "### What are some popular vector store tools?\n",
        "- FAISS (Facebook AI Similarity Search)\n",
        "- Pinecone\n",
        "- Weaviate\n",
        "- Chroma\n",
        "\n",
        "### What is an embedding, and how does it relate to a vector store?\n",
        "An embedding is a numerical representation of data (e.g., text, image) that captures its meaning. These embeddings are stored in a vector store for efficient retrieval.\n",
        "\n",
        "\n",
        "Our next step is\n",
        "-  to convert the `product_description` to chunks\n",
        "-  convert each chunk to embedding\n",
        "-  store it in vector store for searching\n",
        "\n",
        "As discussed earlier we shall use `LangChain` to perform these steps.\n",
        "\n",
        "LangChain is a framework that helps developers build applications powered by large language models (LLMs) like GPT by providing tools for various tasks to be carried out like retrieving relevant information from databases, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwFdqweOT2xI"
      },
      "outputs": [],
      "source": [
        "# Importing RecursiveCharacterTextSplitter from LangChain for chunking large\n",
        "# text into smaller, manageable pieces.\n",
        "# This helps in optimizing text for processing and retrieval.\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Importing OpenAIEmbeddings from LangChain to generate numerical vector\n",
        "# representations (embeddings) of text.\n",
        "# These embeddings capture the semantic meaning of the text for efficient\n",
        "# similarity searches.\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# Importing FAISS (Facebook AI Similarity Search) from LangChain's\n",
        "# community package.\n",
        "# FAISS is used for storing and retrieving embeddings efficiently by finding\n",
        "# similar vectors.\n",
        "from langchain_community.vectorstores import FAISS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2X3hxmTTUsr1"
      },
      "outputs": [],
      "source": [
        "# Setting the OpenAI API key as an environment variable.\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PD-uoBzLVtdw"
      },
      "outputs": [],
      "source": [
        "# Split the input text using Recursive Character Chunking\n",
        "# See this for more details https://python.langchain.com/v0.1/docs/modules/data_connection/document_transformers/recursive_text_splitter/\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=250,\n",
        "    chunk_overlap=20,\n",
        "    length_function=len,\n",
        "    is_separator_regex=False,\n",
        ")\n",
        "documents = text_splitter.create_documents(product_description)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code Explanation:\n",
        "The above code initializes a `RecursiveCharacterTextSplitter` to break down product_description into smaller text chunks of 250 characters each, with a 20-character overlap to preserve context between chunks. The `create_documents` function processes the text list and generates structured document chunks for efficient retrieval and analysis.\n",
        "\n",
        "### Why do we need overlap?\n",
        "Overlap is needed to ensure continuity and preserve context between chunks, preventing important information from being cut off at chunk boundaries.\n",
        "\n",
        "This helps LLMs better understand the text when processing each chunk independently, improving retrieval accuracy and response quality."
      ],
      "metadata": {
        "id": "MqtfA0tXh7CL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ptE8XpNLWD--"
      },
      "outputs": [],
      "source": [
        "# Create an embedding model using LangChain.\n",
        "# One option is using https://python.langchain.com/docs/integrations/text_embedding/openai/\n",
        "# See https://python.langchain.com/docs/integrations/text_embedding/ for a list of available embedding models on LangChain\n",
        "embeddings = OpenAIEmbeddings()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSlO9vblWGDt"
      },
      "outputs": [],
      "source": [
        "# Create a vector store using the created chunks and the embeddings model\n",
        "vector = FAISS.from_documents(documents, embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What have we done so far?\n",
        "1. Data Preparation: Extracted the product description data\n",
        "2. Data Chunking: Converted the entire data into multiple manageable chunks\n",
        "3. Chunks to Embeddings: Converted the broken down chunks into embeddings\n",
        "4. Storage in a Vector DB: Stored the resulting embeddings of chunks in a vector store for effective retrieval.\n",
        "\n",
        "\n",
        "### What is remaining?\n",
        "- Building the chatbot\n",
        "- Building the Gradio UI"
      ],
      "metadata": {
        "id": "nNhCKF9Nig_n"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c24S9JsfWSa7"
      },
      "source": [
        "### STEP 3: Building the chatbot\n",
        "\n",
        "Now that we have converted the documents to embeddings, our next step is to\n",
        "- build a retriever that uses the vector store to retrieve the documents\n",
        "- create a prompt template that contains the augmented context using the retrieved documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nElsMdbeW4l1"
      },
      "outputs": [],
      "source": [
        "# Importing ChatOpenAI from LangChain to interact with OpenAI's language models,\n",
        "# such as GPT, for generating responses.\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Importing ChatPromptTemplate to create structured prompts for the chatbot,\n",
        "# ensuring consistent interactions with the AI model.\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# Importing OpenAIEmbeddings to convert text data into numerical vector\n",
        "# representations for similarity search and retrieval.\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# Importing create_stuff_documents_chain to combine and process retrieved\n",
        "# documents for meaningful AI-generated responses.\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "\n",
        "# Importing create_retrieval_chain to build a chain that retrieves relevant\n",
        "# documents from a vector store and generates AI responses.\n",
        "from langchain.chains import create_retrieval_chain\n",
        "\n",
        "# Importing StrOutputParser from LangChain to parse the output\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Code Explanation:\n",
        "- `ChatOpenAI` – Used to access OpenAI models for chatbot functionality.\n",
        "- `ChatPromptTemplate` – Helps structure queries to ensure better responses.\n",
        "- `OpenAIEmbeddings` – Converts text into vector form for similarity-based retrieval.\n",
        "- `create_stuff_documents_chain` – Combines retrieved documents meaningfully before passing to the LLM.\n",
        "- `create_retrieval_chain` – Automates the process of retrieving and utilizing relevant content for AI responses.\n",
        "- `StrOutputParser` - For processing the output of language models, ensuring that the output is returned as a plain string"
      ],
      "metadata": {
        "id": "xVChvJAijx-1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dJXzILCXStu"
      },
      "outputs": [],
      "source": [
        "# Initializing the ChatOpenAI model to interact with OpenAI's GPT model.\n",
        "llm = ChatOpenAI(api_key=os.environ[\"OPENAI_API_KEY\"], model = 'gpt-4o-mini')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the output parser to process and format the model's response into a readable string format.\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "# Creating a prompt template that instructs the LLM to act as a\n",
        "# customer service agent.\n",
        "# The prompt takes two parameters:\n",
        "#   1. {context} - Relevant information retrieved from the document store.\n",
        "#   2. {input} - The user's question.\n",
        "# The model is instructed to base its answer solely on the provided context.\n",
        "prompt = ChatPromptTemplate.from_template(\n",
        "    \"\"\"Answer the following question based only on the provided context:\n",
        "\n",
        "    <context>\n",
        "    {context}\n",
        "    </context>\n",
        "\n",
        "    Question: {input}\"\"\",\n",
        "    output_parser=output_parser                  # The output parser ensures that the response is returned in a structured string format.\n",
        ")\n",
        "\n",
        "# Creating a document processing chain using the LLM and the defined prompt\n",
        "# template.\n",
        "# This chain takes a list of retrieved documents and passes them as context to\n",
        "# the model for generating responses.\n",
        "document_chain = create_stuff_documents_chain(llm, prompt)\n",
        "\n",
        "# Alternative chain creation method:\n",
        "# Using the \"|\" (pipe) operator to link the prompt with the language model (llm),\n",
        "# meaning the input first goes to the prompt and then to the model for\n",
        "# response generation.\n",
        "# document_chain = prompt | llm\n"
      ],
      "metadata": {
        "id": "dPJ3yFeEk9EN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Code Explanation:\n",
        "- A structured prompt is created using `ChatPromptTemplate` to guide the LLM in answering questions based solely on provided context.\n",
        "- The prompt includes placeholders `{context}` and `{input}` to dynamically inject relevant information.\n",
        "- `StrOutputParser()` ensures that the LLM's response is formatted as plain text for easy processing and display.\n",
        "- `create_stuff_documents_chain(llm, prompt)` combines the language model (LLM) with the prompt to form a processing chain. This chain takes retrieved documents as input and generates AI-driven responses.\n",
        "- Alternate way:  `prompt | llm` is a more concise way to chain the prompt and model, achieving the same functionality with a cleaner syntax."
      ],
      "metadata": {
        "id": "__HKSf_Umiq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a retriever from the vector store for fetching relevant documents\n",
        "# See https://python.langchain.com/v0.1/docs/modules/data_connection/retrievers/vectorstore/\n",
        "retriever = vector.as_retriever()\n",
        "\n",
        "# Create a retrieval chain that first retrieves relevant documents and then processes them using the document chain\n",
        "retrieval_chain = create_retrieval_chain(retriever, document_chain)\n"
      ],
      "metadata": {
        "id": "VMiWghjrl5oB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Code Explanation:\n",
        "- The `vector.as_retriever()` converts the vector store into a retriever to find documents based on query similarity.\n",
        "- The `create_retrieval_chain()` connects the retriever with the document processing pipeline, ensuring the AI receives relevant context before generating responses.\n",
        "\n",
        "This setup enables the AI to provide accurate answers by first retrieving and then processing relevant documents."
      ],
      "metadata": {
        "id": "xY3X-YJZmT3T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUqxhEW3XcJX",
        "outputId": "b6cbe5ce-26ab-4317-e189-5710ac4a7762"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'what are some of the best shoes available?',\n",
              " 'context': [Document(id='030d7be1-3321-4423-859b-73eb92d50838', metadata={}, page_content=\"Title\\nadidas Men's Predator 18+ FG Firm Ground Soccer Cleats\\nDescription\\nadidas Predator 18+ FG- Black 7.5\"),\n",
              "  Document(id='e98e3568-1bb6-41ed-b295-5376c909e042', metadata={}, page_content=\"Title\\nPUMA Cali Sport Clean Women's Sneakers White Leather (37540701)\"),\n",
              "  Document(id='ddf05f60-bc73-4e05-9c84-0f793358146e', metadata={}, page_content=\"Title\\nKenneth Cole REACTION Men's Crespo Loafer B Shoe, Cognac, 10 M US\"),\n",
              "  Document(id='772c1c4b-2a66-4f39-ba95-02c0ecaa0cef', metadata={}, page_content=\"The Remora Climbing Shoe is Mad Rock's do-it-all slipper for climbers who can't have separate shoes for boulders, sport routes, and gyms. With a moderately stiff, slightly downturned design, the Remora performs on any climb at steep to vertical\")],\n",
              " 'answer': \"Based on the provided context, some of the best shoes available include:\\n\\n1. adidas Men's Predator 18+ FG Firm Ground Soccer Cleats\\n2. PUMA Cali Sport Clean Women's Sneakers\\n3. Kenneth Cole REACTION Men's Crespo Loafer B Shoe\\n4. Mad Rock Remora Climbing Shoe \\n\\nThese shoes cater to different activities including soccer, casual wear, formal occasions, and climbing.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "# Invoking the retrieval chain to process the user's query.\n",
        "# The query \"what are some of the best shoes available?\" is passed as input.\n",
        "# The retrieval chain first fetches relevant product descriptions from the vector store,\n",
        "# then processes them using the document chain to generate a meaningful LLM response.\n",
        "retrieval_chain.invoke({\"input\": \"what are some of the best shoes available?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqNvod6GXfjx",
        "outputId": "c895dcc6-4c14-41d5-a995-b068a2dc7fa9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The context provided mentions several specific shoe models, each suited for different activities. Some of the best shoes available based on the context include:\n",
            "\n",
            "1. **adidas Men's Predator 18+ FG Firm Ground Soccer Cleats** - Designed for soccer on firm ground surfaces.\n",
            "2. **PUMA Cali Sport Clean Women's Sneakers** - A stylish white leather sneaker for everyday wear.\n",
            "3. **Kenneth Cole REACTION Men's Crespo Loafer B Shoe** - A cognac-colored loafer suitable for casual or semi-formal occasions.\n",
            "4. **Mad Rock Remora Climbing Shoe** - A versatile climbing shoe for various climbing activities, suitable for both bouldering and sport routes.\n",
            "\n",
            "These options cater to athletic, casual, and specialized needs.\n"
          ]
        }
      ],
      "source": [
        "# Fetching the final answer from the retrieval chain by invoking it with a user query.\n",
        "# The ['answer'] key extracts the final LLM-generated answer from the response dictionary.\n",
        "resp = retrieval_chain.invoke({\"input\": \"what are some of the best shoes available?\"})['answer']\n",
        "print(resp)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we got the answer! But, the formatting is not very good, right? Lets create a simple UI for our bot."
      ],
      "metadata": {
        "id": "2tMQ3SGUnoad"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvDsSk-bYSwS"
      },
      "source": [
        "### STEP 4: Building a simple Gradio UI\n",
        "\n",
        "Gradio is an open-source Python library that makes it easy to build interactive user interfaces for machine learning models, APIs, and data science workflows. It allows developers to create shareable web-based UIs with just a few lines of code.\n",
        "\n",
        "To build the gradio app we'll utilize the following steps:\n",
        "\n",
        "- Modularize the entire RAG pipeline using a single function\n",
        "- Create the building blocks for the UI.\n",
        "- Connect the UI with the function"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to process the user query and return formatted product names\n",
        "def final_response(user_query):\n",
        "    # Invoking the retrieval chain with the user's query to fetch relevant product information\n",
        "    response = retrieval_chain.invoke({\"input\": user_query})['answer']\n",
        "\n",
        "    # Creating a prompt to instruct the LLM to format the response properly\n",
        "    # The prompt asks the LLM to extract only product names from the\n",
        "    # retrieved response\n",
        "    prompt = f\"Format the responses properly in {response}. Just return the product names, no other text\"\n",
        "\n",
        "    # Sending the formatted prompt to the GPT-4o-mini model for processing\n",
        "    openai_response = client.chat.completions.create(\n",
        "        model='gpt-4o-mini',  # Using GPT-4o-mini model for response generation\n",
        "        messages=[{'role': 'user', 'content': prompt}]  # Providing the prompt to the model\n",
        "    )\n",
        "\n",
        "    # Extracting and returning the LLM-generated response containing only the\n",
        "    # product names\n",
        "    return openai_response.choices[0].message.content\n"
      ],
      "metadata": {
        "id": "PcAbbKmKoHZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttosPCA2bLYz",
        "outputId": "b3ae0c1d-d060-4b0b-96ff-298328cfbe58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. adidas Men's Predator 18+ FG Firm Ground Soccer Cleats  \n",
            "2. PUMA Cali Sport Clean Women's Sneakers (White Leather)  \n",
            "3. Kenneth Cole REACTION Men's Crespo Loafer B Shoe (Cognac)  \n",
            "4. Mad Rock Remora Climbing Shoe  \n"
          ]
        }
      ],
      "source": [
        "# Printing the final response\n",
        "print(final_response(\"what are some of the best shoes available?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "jjS_RUh6ZstZ",
        "outputId": "ed3d4e1f-3f7c-4c5b-9e07-25eb526a33ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gradio/interface.py:403: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://27dbcbd1f342dee386.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://27dbcbd1f342dee386.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "# Importing the Gradio library to create a simple web-based user interface\n",
        "import gradio as gr\n",
        "\n",
        "# Creating the Gradio interface for the product recommendation system\n",
        "app = gr.Interface(\n",
        "    fn=final_response,        # The function that processes user input and returns recommendations\n",
        "    inputs=\"text\",            # Input component: a text box for users to enter their query\n",
        "    outputs=\"text\",           # Output component: a text box to display the AI-generated response\n",
        "    title=\"Review Genie\",     # The title of the web interface\n",
        "    description=\"Type your question below to get the recommendations\",# A brief description displayed to users\n",
        "    theme=\"Ocean\",\n",
        "    allow_flagging=\"never\"    # Disabling the flagging feature to remove the \"Flag\" button\n",
        ")\n",
        "\n",
        "# Launching the Gradio app to start the interface and make it accessible via web browser\n",
        "app.launch()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What are the limitations in this?\n",
        "### Limitations of the LLMs\n",
        "\n",
        "Large Language Models (LLMs) like ChatGPT, GPT-4, and other AI systems are incredibly powerful, but they have a key limitation: they rely on pre-trained knowledge, which becomes outdated over time.\n",
        "\n",
        "Earlier we saw how Retrieval Augmented Generation (RAG) solves this problem by providing access to external knowledge sources and improve the responses from the LLMs. However, these external knowledge sources are static resources and can also get outdated after a period of time.\n",
        "\n",
        "Take the following example:\n",
        "\n",
        "`\"What was the Stock Price average of Uber in the last week?\"`\n",
        "\n",
        "If we were to design an AI system using RAG for answering questions as above, it would require a constant update of the knowledge base every week. This can be an expensive and inefficient process. A much better way to implement this would be to use **Agentic Tools** that can retrieve real-time information.\n",
        "\n",
        "This is where ***Tavily*** plays a crucial role by integrating real-time web search capabilities to keep AI responses up-to-date and contextually relevant.\n",
        "\n",
        "#### How does Tavily improve it?\n",
        "- Tavily enables live searches to retrieve the latest news, research papers, and real-world updates.\n",
        "- LLMs have a knowledge cutoff (e.g., ChatGPT may not know recent events). Tavily enables AI to bridge this gap by fetching real-time data from the web.\n",
        "\n",
        "So, let's set up the API key for using this in our project.\n",
        "It's FREE!!!!!!\n",
        "\n",
        "### TAVILY SETUP\n",
        "\n",
        "- Go to Tavily's web page - https://tavily.com/\n",
        "- Click on Sign Up. You can create a new account or sign up using your Google/Github account.\n",
        "- Once you successfully sign up, you will then be redirected to the Overview Dashboard as shown below. Your API key will be visible there as shown below (You get 1000 Free API Credits to use)\n"
      ],
      "metadata": {
        "id": "jLhZPGPbqype"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up the Tavily API Key to do web search\n",
        "os.environ[\"TAVILY_API_KEY\"] = getpass.getpass()"
      ],
      "metadata": {
        "id": "3qXu67oiq86T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import the 'tool' decorator\n",
        "from langchain.tools import tool\n",
        "from langchain.tools.retriever import create_retriever_tool\n",
        "\n",
        "# Define a tool for Amazon product search using @tool decorator\n",
        "@tool\n",
        "def amazon_product_search(query: str):\n",
        "    \"\"\"Search for information about Amazon products.\n",
        "    For any questions related to Amazon products, this tool must be used.\"\"\"\n",
        "\n",
        "    # Create the retriever tool\n",
        "    retriever_tool = create_retriever_tool(\n",
        "        retriever,  # The retriever object that fetches Amazon product data\n",
        "        name=\"amazon_search\",\n",
        "        description=\"Search for information about Amazon products.\"\n",
        "    )\n",
        "\n",
        "    # Execute search based on query\n",
        "    return retriever_tool.invoke(query)"
      ],
      "metadata": {
        "id": "fda7xM1eq-Il"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code Explanation:\n",
        "\n",
        "- Importing `create_retriever_tool`:\n",
        "\n",
        "`create_retriever_tool` is a utility function in LangChain that allows you to wrap a retriever (a component that fetches relevant information from a data source) into a tool that can be used within an AI workflow.\n",
        "\n",
        "- Creating the `retriever_tool`:\n",
        "    - **retriever:** This is a retriever instance (coded in the previous class).\n",
        "    - **name=\"amazon_search\":** Defines the tool's name, which helps identify it when used in multi-tool environments.\n",
        "    - **description:** Provides a natural language description of what the tool does, which helps AI models understand when to invoke it."
      ],
      "metadata": {
        "id": "Mhk3jDZ0rDXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary classes from LangChain for Tavily integration\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "@tool\n",
        "def search_tavily(query: str):\n",
        "    \"\"\"\n",
        "    Executes a web search using the TavilySearchResults tool.\n",
        "\n",
        "    Parameters:\n",
        "        query (str): The search query entered by the user.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of search results containing answers, raw content, and images.\n",
        "    \"\"\"\n",
        "    # Create an instance of TavilySearchResults with customized parameters\n",
        "    search_tool = TavilySearchResults(\n",
        "        max_results=5,  # Retrieves up to 5 search results\n",
        "        include_answer=True,  # Includes direct answers when available\n",
        "        include_raw_content=True,  # Includes full raw text content from search results\n",
        "        include_images=True,  # Includes images from the search results\n",
        "    )\n",
        "\n",
        "    # Invoke the search with the given query and return the results\n",
        "    return search_tool.invoke(query)\n",
        "\n"
      ],
      "metadata": {
        "id": "YcHL2VCtrD-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code Explanation:\n",
        "\n",
        "`search_tavily(query: str)`:\n",
        "This function initializes TavilySearchResults with the following parameters & returns the results for the user query:\n",
        "\n",
        "    - `max_results=5`: Limits the number of search results to 5.\n",
        "    - `include_answer=True`: Retrieves direct answers when available.\n",
        "    - `include_raw_content=True`: Fetches full raw text content from the search results.\n",
        "    - `include_images=True`: Includes images found in the search results.\n",
        "\n",
        "\n",
        "### Example:\n",
        "If the chatbot needs real-time information (e.g., latest stock prices, news, or research articles), it can call TavilySearch to retrieve fresh data from the web.\n",
        "**Example Query:**\n",
        "- User: \"What are the latest AI trends in 2025?\"\n",
        "- AI (using TavilySearch) → Fetches 5 recent web search results and summarizes them in the response.\n",
        "\n"
      ],
      "metadata": {
        "id": "5xVd4XcfrJg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# hwchase17/react is a prompt template designed for ReAct-style\n",
        "# conversational agents.\n",
        "prompt = hub.pull(\"hwchase17/react\")"
      ],
      "metadata": {
        "id": "O-tFFAiLrKaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prompt.template)"
      ],
      "metadata": {
        "id": "rcj4VYITrOzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code Explanation:\n",
        "- **Pulling a Prompt from LangChain Hub (hub.pull())**\n",
        "LangChain Hub provides predefined prompt templates that can be used in AI applications.\n",
        "    - The \"hwchase17/react-chat\" prompt is a ReAct (Reasoning + Acting) style prompt optimized for conversational AI.\n",
        "    - The pulled prompt will define how an AI agent should structure responses.\n",
        "\n",
        "**Example scenario:**\n",
        "    - User: \"What’s the latest AI research?\"\n",
        "    - AI: (Fetches real-time research using Tavily and provides an answer.)\n"
      ],
      "metadata": {
        "id": "zcy0kDfPrSXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Create a list of tools: retriever_tool and search_tool\n",
        "tools = [search_tavily, amazon_product_search]"
      ],
      "metadata": {
        "id": "K-cVREfkrS3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "react_agent = create_react_agent(\n",
        "    llm=llm,  # The OpenAI model responsible for reasoning and response generation.\n",
        "    tools=tools,  # A list of external tools (e.g., web search, product retrieval).\n",
        "    prompt=prompt  # The ReAct-style prompt guiding the agent's thought process.\n",
        ")"
      ],
      "metadata": {
        "id": "-lYOVJX5rVtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# executes the logical steps we created\n",
        "agent_executor = AgentExecutor(\n",
        "    agent=react_agent,\n",
        "    tools=tools,\n",
        "    verbose=True,\n",
        "    handle_parsing_errors=True,\n",
        "    max_iterations = 5 # useful when agent is stuck in a loop\n",
        ")"
      ],
      "metadata": {
        "id": "J3We6CG0rXji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code Explanation\n",
        "\n",
        "1. Initialize the OpenAI Language Model (LLM):\n",
        " - OpenAI's completion-based model is used to generate responses.\n",
        " - Setting `temperature=0` ensures deterministic and factual responses.\n",
        " - A lower temperature reduces randomness, making responses more structured.\n",
        "\n",
        "2. Creating the ReAct Agent:\n",
        " - The agent follows the ReAct framework (Reasoning + Acting).\n",
        " - It first thinks through the query and then decides whether to call a tool.\n",
        " - If a tool is required, it invokes the appropriate one before responding.\n",
        "\n",
        "3. Initializing the Agent Executor:\n",
        " - The AgentExecutor handles query execution and tool invocation.\n",
        " - It decides when the agent should call a tool vs. answer directly.\n",
        " - The verbose mode provides detailed logs to track agent reasoning and tool interactions.\n"
      ],
      "metadata": {
        "id": "SIXn5K_3rZYd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's try some examples\n",
        "\n",
        "#### Questions that use Amazon tool only"
      ],
      "metadata": {
        "id": "u9IecUdZrj2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res = agent_executor.invoke({\"input\": \"What is the best shoes I can find on Amazon?\"})"
      ],
      "metadata": {
        "id": "TfmL20kvro8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(res['output'])"
      ],
      "metadata": {
        "id": "onxyFM1Trw8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Questions that use the search tool only"
      ],
      "metadata": {
        "id": "hTEEXF-Grz66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res = agent_executor.invoke({\"input\": \"What is the current weather in Toronto?\"})"
      ],
      "metadata": {
        "id": "mm3hNEMlr0p4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(res['output'])"
      ],
      "metadata": {
        "id": "UHXbuTzxr5db"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Questions that use both tools"
      ],
      "metadata": {
        "id": "G2fHuhqAr6Ch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res = agent_executor.invoke({\"input\": \"How to install Backsplash Wallpaper? Also find some brands on Amazon\"})"
      ],
      "metadata": {
        "id": "S8JZtJTxr9g0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(res['output'])"
      ],
      "metadata": {
        "id": "3SprzA8GsCPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adding Memory and Multi-turn Capabilities\n",
        "\n",
        "### What is a multi-turn conversation?\n",
        "<center><img src=\"https://poly.ai/wp-content/uploads/2020/12/Blog-post-graphics_Multi-1.png\"/></center>\n",
        "\n",
        "A multi-turn conversation is an interactive dialogue where the AI retains context across multiple exchanges, allowing for a natural back-and-forth flow instead of handling each query in isolation.\n",
        "\n",
        "Example:\n",
        "User: \"What's the weather like in New York?\"\n",
        "AI: \"It's 10°C and cloudy.\"\n",
        "User: \"What about tomorrow?\"\n",
        "AI: \"Tomorrow, it will be 12°C with light rain.\"\n",
        "\n",
        "Here, the AI remembers \"New York\" from the first query, maintaining context instead of requiring the user to repeat it.\n",
        "\n",
        "\n",
        "A multi-turn conversation relies on **memory** to retain context across exchanges, enabling AI to respond meaningfully without requiring repeated inputs.\n",
        "\n",
        "Adding memory component to the application has several advantages as follows:\n",
        "\n",
        "1. **Context Retention** – Enables natural and coherent conversations by remembering past interactions.  \n",
        "2. **Personalization** – Adapts responses based on user history and preferences for a better experience.  \n",
        "3. **Multi-Turn Conversations** – Supports complex queries and step-by-step interactions without losing track.  \n",
        "4. **Efficiency & Reduced Repetition** – Eliminates the need for users to repeat information, improving usability.  \n",
        "5. **Enhanced User Satisfaction** – Creates a more human-like, engaging, and helpful chatbot experience."
      ],
      "metadata": {
        "id": "3BSoKqf-seyM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a Prompt Template\n",
        "\n",
        "# Pull a predefined prompt from LangChain Hub\n",
        "# \"hwchase17/react-chat\" is a prompt template designed for ReAct-style conversational agents.\n",
        "prompt = hub.pull(\"hwchase17/react-chat\")\n",
        "\n",
        "# Initialize a chat message history object with a session ID\n",
        "# This stores the conversation history for a given session, allowing stateful interactions.\n",
        "memory = ChatMessageHistory(session_id=\"test-session\")\n",
        "memory.clear()"
      ],
      "metadata": {
        "id": "-9_6CKEcsfdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an Agent with Chat History to maintain conversation context\n",
        "agent_with_chat_history = RunnableWithMessageHistory(\n",
        "    agent_executor,  # The main AgentExecutor responsible for executing queries and invoking tools.\n",
        "\n",
        "    lambda session_id: memory,\n",
        "\n",
        "    input_messages_key=\"input\",  # Specifies the key in the input dictionary where the user query is stored.\n",
        "\n",
        "    history_messages_key=\"chat_history\",  # Specifies the key under which the conversation history is stored.\n",
        ")"
      ],
      "metadata": {
        "id": "gyzW4Xjzsj_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code Explanation:\n",
        "\n",
        "- Initializing an Agent with chat history:\n",
        " - `session_id` is useful in real-world applications where session tracking is required. Here, it simply returns the in-memory chat history for simplicity.\n",
        " - `RunnableWithMessageHistory` ensures the agent retains context across multiple interactions. This is useful for multi-turn conversations where past messages influence future responses.\n"
      ],
      "metadata": {
        "id": "JMSdY53LsmcK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Invoke the agent with chat history\n",
        "# Let's try a query based on recent data and check whether 'Tavily Search' is triggered\n",
        "agent_with_chat_history.invoke(\n",
        "    {\"input\": \"What is the latest fashion trends in 2025?\"},\n",
        "    config={\"configurable\": {\"session_id\": \"<foo>\"}},\n",
        ")\n"
      ],
      "metadata": {
        "id": "OfJA6D3RsnDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Invoke the agent with chat history\n",
        "# Let's try a query based on amazon data & check if 'amazon_search' tool is triggered\n",
        "agent_with_chat_history.invoke(\n",
        "    {\"input\": \"Can I get these trends from Amazon?\"},\n",
        "    config={\"configurable\": {\"session_id\": \"<foo>\"}},\n",
        ")\n"
      ],
      "metadata": {
        "id": "G6-JqmtXsqxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What Next?\n",
        "\n",
        "- Try a gradio UI for the optimized version of your chatbot.\n",
        "- Experiment with various parameters and understand how the output varies!\n",
        "\n",
        "<hr>"
      ],
      "metadata": {
        "id": "xy1vhD6Js0Gf"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}